# ğŸ§¹ SQL Data Cleaning Project

## ğŸ“Œ Overview
This project demonstrates SQL data cleaning skills by transforming and preparing raw layoff data for analysis. Tasks include removing duplicates, handling nulls, formatting inconsistencies, and generating cleaned datasets.

## ğŸ—‚ Dataset
- Source: [Insert dataset source or mention "dummy data"]
- Format: CSV / MySQL Table

## âš™ï¸ Tools Used
- MySQL / PostgreSQL / SQL Server
- SQL Queries (ROW_NUMBER, CTEs, CASE, TRIM, UPPER, JOIN, etc.)

## ğŸ›  Key SQL Skills Applied
- âœ… CTEs for temporary data views
- âœ… Window functions for duplicate detection
- âœ… CASE WHEN for conditional logic
- âœ… Data standardization (TRIM, LOWER, etc.)
- âœ… NULL value handling

## ğŸš€ Cleaning Steps Performed
1. Removed exact and partial duplicates using `ROW_NUMBER()`
2. Replaced NULLs with default values
3. Standardized inconsistent company names
4. Removed irrelevant rows
5. Exported the final cleaned data

## ğŸ“Š Result
- 1000+ rows cleaned
- Ready for Power BI/Excel/Tableau visualizations
- Clean dataset with reliable schema

## ğŸ’¡ Future Improvements
- Automate data load using Python
- Integrate with Power BI dashboard

## ğŸ§  What I Learned
- How to write optimized SQL scripts for data transformation
- Real-world challenges in cleaning unstructured data
- The importance of CTEs and window functions in data deduplication
